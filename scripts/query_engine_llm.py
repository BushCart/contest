from sentence_transformers import SentenceTransformer
import faiss
import pickle
from pathlib import Path
from ollama import Client
import tiktoken

INDEX_PATH = Path("vector_store/faiss.index")
META_PATH = Path("vector_store/metadata.pkl")
MAX_TOKENS = 1500

ollama = Client(host="http://localhost:11434")
embedder = SentenceTransformer('intfloat/multilingual-e5-base')
index = faiss.read_index(str(INDEX_PATH))
enc = tiktoken.get_encoding("cl100k_base")

with META_PATH.open("rb") as f:
    metadata = pickle.load(f)


def count_tokens(text: str) -> int:
    return len(enc.encode(text))

def rerank(query: str, candidates: list[dict], top_k: int = 5) -> list[dict]:
    scored = []
    system_prompt = (
        "–¢—ã ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏. "
        "–û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 1 (–¥—Ä–æ–±–Ω–æ–µ —á–∏—Å–ª–æ —Å —Ç–æ—á–∫–æ–π), –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ —á–∏—Å–ª–∞. "
        "–ù–∏–∫–∞–∫–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –¥—Ä—É–≥–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤. "
        "–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî 0. –ï—Å–ª–∏ –æ—á–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω ‚Äî 1."
    )

    for candidate in candidates:
        prompt = (
            f"–í–æ–ø—Ä–æ—Å: {query}\n\n"
            f"–¢–µ–∫—Å—Ç: {candidate['text']}\n\n"
            f"–û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0-1):"
        )
        try:
            resp = ollama.chat(
                model="mistral",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ]
            )
            score_str = resp['message']['content'].strip()
            score = float(score_str)
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –ø—Ä–∏ rerank: {e}")
            score = 0.0
        
        candidate_with_score = candidate.copy()
        candidate_with_score["score"] = score
        scored.append(candidate_with_score)
    
    scored_sorted = sorted(scored, key=lambda x: x["score"], reverse=True)
    return scored_sorted[:top_k]


def get_confidence(filtered: list[dict]) -> str:
    min_dist = min(r["distance"] for r in filtered)
    if min_dist < 0.35:
        return "üü¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –≤—ã—Å–æ–∫–∞—è"
    elif min_dist < 0.55:
        return "üü° –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: —Å—Ä–µ–¥–Ω—è—è"
    else:
        return "üî¥ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –Ω–∏–∑–∫–∞—è"

def build_context(filtered: list[dict]) -> tuple[str, list[dict]]:
    context_chunks = []
    token_total = 0
    used = []

    for r in filtered:
        tokens = count_tokens(r["text"])
        if token_total + tokens > MAX_TOKENS:
            break
        context_chunks.append(r["text"])
        token_total += tokens
        used.append({
            "page": r["page"],
            "id":   r["id"],
            "source": r["source"]
        })

    return "\n---\n".join(context_chunks), used

def search(query: str, top_k: int = 5) -> list[dict]:
    query_vec = embedder.encode(["query: " + query]).astype("float32")
    distances, ids = index.search(query_vec, top_k)

    results = []
    for idx, dist in zip(ids[0], distances[0]):
        meta = metadata[idx]
        results.append({
            "id":       idx,
            "distance": float(dist),
            "text":     meta.get("text", ""),
            "source":   meta.get("source", ""),
            "page":     meta.get("page", "?")
        })
    return results


def generate_answer(
    question: str,
    search_k: int = 10,
    rerank_k: int = 5
):
    try:
        results = search(question, top_k=search_k)
        reranked = rerank(question, results, top_k=rerank_k)

        if not reranked:
            print("üî¥ –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –û—Ç–≤–µ—Ç –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
            return

        confidence = get_confidence(reranked)
        context, used_chunks = build_context(reranked)
        system = (
            """
            –í—ã ‚Äî –ø—Ä–∏—ë–º–Ω–∞—è –∫–æ–º–∏—Å—Å–∏—è –ò–¢–ú–û. –í–∞—à–∏ –∑–Ω–∞–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã —Ç–æ–ª—å–∫–æ –¥–≤—É–º—è –º–∞–≥–∏—Å—Ç–µ—Ä—Å–∫–∏–º–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º–∏:
            1) ¬´–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç¬ª (AI)
            2) ¬´AI Product¬ª

            –ü–û–†–Ø–î–û–ö –î–ò–ê–õ–û–ì–ê:
            1. –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ ‚Äî —É—Ç–æ—á–Ω–∏—Ç–µ: ¬´–ö–∞–∫—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É –≤—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç–µ: AI –∏–ª–∏ AI Product?¬ª
            2. –ö–∞–∫ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–±—Ä–∞–Ω–∞, —Å–ø—Ä–æ—Å–∏—Ç–µ: ¬´–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –≤–∫—Ä–∞—Ç—Ü–µ –æ –≤–∞—à–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∏–ª–∏ –æ–ø—ã—Ç–µ.¬ª
            3. –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –±—ç–∫–≥—Ä–∞—É–Ω–¥–∞ ‚Äî –¥–∞–π—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ 3‚Äì5 –≤—ã–±–æ—Ä–Ω—ã–º –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞–º –∏–∑ —ç—Ç–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏–π –∫—É—Ä—Å–æ–≤ –∏ —Ä–∞—Å—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ñ–æ–Ω–∞.
            4. –ó–∞—Ç–µ–º –æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –ª—é–±—ã–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã —Ç–æ–ª—å–∫–æ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É —ç—Ç–∏—Ö —É—á–µ–±–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤.
            –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ —ç—Ç–∏—Ö –¥–≤—É—Ö –ø—Ä–æ–≥—Ä–∞–º–º, –≤–µ–∂–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞–π—Ç–µ:  
            ¬´–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –º–æ–≥—É –ø–æ–º–æ—á—å —Ç–æ–ª—å–∫–æ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø–æ —É—á–µ–±–Ω—ã–º –ø–ª–∞–Ω–∞–º AI –∏ AI Product.¬ª
            """
        )
        prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:"

        resp = ollama.chat(
            model="mistral",
            messages=[
                {"role": "system", "content": system},
                {"role": "user",   "content": prompt}
            ]
        )
        answer = resp['message']['content'].strip()

        sources = [
            f"{chunk['source']} ‚Äî —Å—Ç—Ä. {chunk['page']}"
            for chunk in used_chunks
        ]

        return answer, confidence, sources

    except Exception:
        return (
            "[‚úó] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            "üî¥ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞",
            []
        )


if __name__ == "__main__":
    q = input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å: ")
    ans, conf, srcs = generate_answer(q)
    print(f"\nüîç –û—Ç–≤–µ—Ç ({conf}):\n{ans}\n")
    if srcs:
        print("üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:")
        for s in srcs:
            print(f"- {s}")


